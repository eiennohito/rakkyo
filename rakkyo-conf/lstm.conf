batch = 80000

input.base = {
  compression = GZIP
  batch = ${batch}
  parallel_parse = 1
  parallel_reads = 1
}

period = 120

input.kyoto.test = ${input.base} {
  pattern = "/path/to/full-kyoto-test/data/*.gz"
  period = ${period}
}

input.kyoto.train = ${input.base} {
  pattern = "/path/to/full-kyoto-test/data/*.gz"
  period = ${period}
}

input.lead.test = ${input.base} {
  pattern = "/path/to/full-kyoto-test/*.gz"
  period = ${period}
}

input.lead.train = ${input.base} {
  pattern = "/path/to/full-kyoto-test/data/*.gz"
  period = ${period}
}

epochs = 1

# modify paths to silver data
input.train = ${input.base} {
  pattern = "/path/to/silver/data/*.gz"
  epochs = ${epochs}
  shuffle_buffer = 500000
  shuffle_files = 100
  parallel_reads = 3
}


# For training on mixed Gold/Sinver data use this definition of train dataset
# instead of the default one

# max_examples = 500000000
# silver_window = 30
# silver_corp = xinp-xdfs-02

# input.train = ${input.base} {
#   sources = [{
#     pattern = "/path/to/"${silver_corp}"/data/*.gz"
#     epochs = ${epochs}
#     parallel_reads = 3
#     window = ${silver_window}
#   }, {
#     pattern = "/path/to/full-both-train/data/*.gz"
#     epochs = -1
#   }]

# this section defines what will be used for evaluation/validation
# code versus the config section defining the dataset
# config section period value specifies how often the evaluation will be run
eval {
  # kyoto-train: input.kyoto.train
  # leads-train: input.lead.train
  # kyoto-test: input.kyoto.test
  # leads-test: input.lead.test
}

optimizer = {
  type = adam
  warmup = 2000
  warmup = ${?opt_warmup}
  lrate = ${?opt_lrate}
  beta1 = ${?opt_beta1}
  beta2 = ${?opt_beta2}
  decay = ${?opt_decay}
}

session {
  nthreads_inter = 2
  nthreads_intra = 1
}

dic_basedir = "/path/to/dics-02"

dics = {
  chars = ${dic_basedir}"/chars.bycode.vdic"
  seg = ${dic_basedir}/"seg.vdic"
  pos = ${dic_basedir}/"pos.vdic"
  subpos = ${dic_basedir}/"subpos.vdic"
  ctype = ${dic_basedir}/"ctype.vdic"
  cform = ${dic_basedir}/"cform.vdic"
}

num_tags = 5

char.embed.size = 128

layer_size = 128
layer_repeat = 3
layer_cell = lstm
layer_norm = true
layer_resid = false
layer_dkeep = 1.0

layers = [{
  type = rnn
  size = ${layer_size}
  cell = ${layer_cell}
  normalize = ${layer_norm}
  dropout_keep = ${layer_dkeep}
}, {
  type = rnn
  repeat = ${layer_repeat}
  cell = ${layer_cell}
  normalize = ${layer_norm}
  residual = ${layer_resid}
  dropout_keep = ${layer_dkeep}
}]

tag_smooth = 0.2
tag_smooth_exp = true
tag_smooth_oside = true

seg_weight = 10
pos_weight = 2

embed.tags = 32

tags = [{
    name = seg
    smoothing = ${tag_smooth}
    exp_smoothing = ${tag_smooth_exp}
    one_sided = ${tag_smooth_oside}
    weight = ${seg_weight}
}, {
    name = pos
    smoothing = ${tag_smooth}
    exp_smoothing = ${tag_smooth_exp}
    one_sided = ${tag_smooth_oside}
    weight = ${pos_weight}
}, {
    name = subpos
    smoothing = ${tag_smooth}
    exp_smoothing = ${tag_smooth_exp}
    one_sided = ${tag_smooth_oside}
}, {
    name = ctype
    smoothing = ${tag_smooth}
    exp_smoothing = ${tag_smooth_exp}
    one_sided = ${tag_smooth_oside}
}, {
    name = cform
    smoothing = ${tag_smooth}
    exp_smoothing = ${tag_smooth_exp}
    one_sided = ${tag_smooth_oside}
}]

times {
  # frequency of metrics for tensorboard
  eval = 5
  # frequency of model snapshots
  snapshot = 150
}

prefix = lstm-nc
snapshot_dir = ${?XMRPH_SNAPSHOT_DIR}
full_snapshot_dir = ${snapshot_dir}/${?prefix}